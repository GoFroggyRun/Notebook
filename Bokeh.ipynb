{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from taxcalc.records import Records\n",
    "from taxcalc import Policy, Records, Calculator, Behavior, behavior\n",
    "from taxcalc.utils import *\n",
    "from numpy.testing import assert_array_almost_equal\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.transforms import BlendedGenericTransform\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You loaded data for 2009.\n",
      "Your data have been extrapolated to 2013.\n",
      "You loaded data for 2009.\n",
      "Your data have been extrapolated to 2013.\n"
     ]
    }
   ],
   "source": [
    "puf = pd.read_csv(\"../puf.csv\")\n",
    "policy_base = Policy()\n",
    "records_base = Records(puf)\n",
    "\n",
    "policy_reform = Policy()\n",
    "records_reform = Records(puf)\n",
    "\n",
    "calcbase = Calculator(policy = policy_base, records = records_base)\n",
    "calcreform = Calculator(policy = policy_reform, records = records_reform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reform = {\n",
    "          2015:{\n",
    "        \"_ID_InterestPaid_HC\":[0.5],\n",
    "        \"_ID_StateLocalTax_HC\":[0.5],\n",
    "        \"_ID_Charity_HC\":[0.5]\n",
    "    }\n",
    "}\n",
    "policy_reform.implement_reform(reform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calcbase.advance_to_year(2015)\n",
    "calcreform.advance_to_year(2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calcbase.calc_all()\n",
    "calcreform.calc_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "RES_COLUMNS = STATS_COLUMNS + ['e00200'] + ['MARS'] + ['n24']\n",
    "# The results function selects the data frame we'll be using \n",
    "def results(c):\n",
    "    outputs = []\n",
    "    for col in RES_COLUMNS:\n",
    "        if hasattr(c.policy, col):\n",
    "            outputs.append(getattr(c.policy, col))\n",
    "        else:\n",
    "            outputs.append(getattr(c.records, col))\n",
    "    return DataFrame(data=np.column_stack(outputs), columns=RES_COLUMNS)\n",
    "\n",
    "# EPSILON is defined here to avoid division by zero \n",
    "EPSILON = 1e-3\n",
    "\n",
    "# Calculating the weighted average MTR w.r.t wage\n",
    "def wage_weighted(agg, col_name):\n",
    "    return (float((agg[col_name] * agg['s006'] * agg['e00200']).sum())/\n",
    "            ((agg['s006']*agg['e00200']).sum() + EPSILON))\n",
    "\n",
    "# Calculating the weighted average MTR\n",
    "def weighted(agg, col_name):\n",
    "    return (float((agg[col_name] * agg['s006']).sum())/\n",
    "            ((agg['s006']).sum() + EPSILON))\n",
    "\n",
    "def add_income_bins(df, num_bins, tab):\n",
    "    # First, sort by income_measure\n",
    "    df.sort(tab, inplace=True)\n",
    "    # Next, do a cumulative sum by the weights\n",
    "    df['cumsum_weights'] = np.cumsum(df['s006'].values)\n",
    "    # Max value of cum sum of weights\n",
    "    max_ = df['cumsum_weights'].values[-1]\n",
    "    # Create 100 bins and labels based on this cumulative weight\n",
    "    bin_edges = [0] + list(np.arange(1, (num_bins+1)) * (max_ / float(num_bins)))\n",
    "    labels = range(1, (num_bins+1))\n",
    "    #  Groupby weighted deciles\n",
    "    df['bins'] = pd.cut(df['cumsum_weights'], bins=bin_edges, labels=labels)\n",
    "    return df\n",
    "\n",
    "def print_data(calcX, calcY, weights, tab):\n",
    "    df_x = results(calcX)\n",
    "    df_y = results(calcY)\n",
    "    \n",
    "    id_itemizers_x = ((calcX.records.c04470 > 0) & (calcX.records.c00100 > 0))\n",
    "    id_itemizers_y = ((calcY.records.c04470 > 0) & (calcY.records.c00100 > 0))\n",
    "    df_x['pct_itm'] = id_itemizers_x\n",
    "    df_y['pct_itm'] = id_itemizers_y\n",
    "    \n",
    "    \n",
    "    df_y[tab] = df_x[tab]\n",
    "    \n",
    "    df_x = add_income_bins(df_x, 100, tab)\n",
    "    df_y = add_income_bins(df_y, 100, tab)  \n",
    "    \n",
    "    df_filtered_x = df_x.copy()\n",
    "    df_filtered_y = df_y.copy()\n",
    "    \n",
    "    gp_x = df_filtered_x.groupby('bins', as_index=False)\n",
    "    gp_y = df_filtered_y.groupby('bins', as_index=False)\n",
    "    wgtpct_x = gp_x.apply(weights, 'pct_itm')\n",
    "    wgtpct_y = gp_y.apply(weights, 'pct_itm')\n",
    "    #Add the bin labels\n",
    "    wpct_x = DataFrame( data=wgtpct_x, columns=['w_pct'])\n",
    "    wpct_y = DataFrame( data=wgtpct_y, columns=['w_pct'])\n",
    "    \n",
    "    wpct_x['bins'] = np.arange(1, 101)\n",
    "    wpct_y['bins'] = np.arange(1, 101)\n",
    "    #Join df_x and appld on the bin, carrying along 'w_mtr'\n",
    "    #Left join means that 'rslt' is of size len(df_filtered_x)\n",
    "    rsltx = pd.merge(df_filtered_x[['bins']], wpct_x, how='left')\n",
    "    rslty = pd.merge(df_filtered_y[['bins']], wpct_y, how='left')\n",
    "\n",
    "    # Put that column in df_filtered_x, disregarding index of rslt\n",
    "    df_filtered_x['w_pct'] = rsltx['w_pct'].values\n",
    "    df_filtered_y['w_pct'] = rslty['w_pct'].values\n",
    "    \n",
    "    df_filtered_x.drop_duplicates(subset = 'bins', inplace = True)\n",
    "    df_filtered_y.drop_duplicates(subset = 'bins', inplace = True)\n",
    "    \n",
    "    df_filtered_x.to_csv('base.csv',float_format = '%1.3f',sep=',',header = True, index =False)\n",
    "    df_filtered_y.to_csv('reform.csv',float_format = '%1.3f',sep=',',header = True, index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seanwang/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:29: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "print_data(calcbase, calcreform, weights = weighted, tab = 'c00100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
